{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBqL4W8Chxi9"
   },
   "source": [
    "#Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tVeHtQDhzed"
   },
   "source": [
    "This notebook is a easy guide for training and testing of anomaly detection based on MVTec https://github.com/AdneneBoumessouer/MVTec-Anomaly-Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uESknW72h8u5"
   },
   "source": [
    "###Link Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MecSmAFxlX66"
   },
   "source": [
    "#Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5ZvfjkglvRL"
   },
   "source": [
    "### Directory Structure using your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1UD1k1Blj6E"
   },
   "source": [
    "To train with your own dataset, you need to have a comparable directory structure. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1632215269264,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699857406068047110"
     },
     "user_tz": -180
    },
    "id": "08vGmfeplXv0"
   },
   "outputs": [],
   "source": [
    "#data\n",
    "  #├── class1\n",
    "  # │   ├── test\n",
    "  # │   │   ├── good\n",
    "  # │   │   ├── defect\n",
    "  # │   └── train\n",
    "  # │       └── good\n",
    "  # ├── class2\n",
    "  # │   ├── test\n",
    "  # │   │   ├── good\n",
    "  # │   │   ├── defect\n",
    "  # │   └── train\n",
    "  # │       └── good\n",
    "  # ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aacA9vucmQHq"
   },
   "source": [
    "#Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1632215271041,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699857406068047110"
     },
     "user_tz": -180
    },
    "id": "8vn8bS_JnGwj"
   },
   "outputs": [],
   "source": [
    "# During training, the CAE trains exclusively on defect-free images and learns to reconstruct (predict) defect-free training samples.\n",
    "\n",
    "# usage: train.py [-h] -d [-a] [-c] [-l] [-b] [-i]\n",
    "\n",
    "# optional arguments:\n",
    "\n",
    "# -h, --help show this help message and exit\n",
    "\n",
    "# -d , --input-dir directory containing training images\n",
    "\n",
    "# -a , --architecture architecture of the model to use for training: 'mvtecCAE', 'baselineCAE', 'inceptionCAE' or 'resnetCAE'\n",
    "\n",
    "# -c , --color color mode for preprocessing images before training: 'rgb' or 'grayscale'\n",
    "\n",
    "# -l , --loss loss function to use for training: 'mssim', 'ssim' or 'l2'\n",
    "\n",
    "# -b , --batch batch size to use for training\n",
    "\n",
    "# -i, --inspect generate inspection plots after training\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# python3 train.py -d mvtec/capsule -a mvtecCAE -b 8 -l ssim -c grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1885344,
     "status": "ok",
     "timestamp": 1632223364650,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699857406068047110"
     },
     "user_tz": -180
    },
    "id": "u7yvOxdedpRS",
    "outputId": "692e34df-7511-4186-f961-5f7187fae441",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 train.py -d data/can -a mvtecCAE -b 4 -l ssim -c grayscale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXNG2EaPnOBF"
   },
   "source": [
    "#Finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBKfp4uCjXDo"
   },
   "outputs": [],
   "source": [
    "# This script used a subset of defect-free training images and a subset of both defect and defect-free test images to determine good values for minimum defect area and threshold pair of parameters that will be used during testing for classification and segmentation.\n",
    "\n",
    "# usage: finetune.py [-h] -p [-m] [-t]\n",
    "\n",
    "# optional arguments: -h, --help show this help message and exit\n",
    "\n",
    "# -p , --path path to saved model\n",
    "\n",
    "# -m , --method method for generating resmaps: 'ssim' or 'l2'\n",
    "\n",
    "# -t , --dtype datatype for processing resmaps: 'float64' or 'uint8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuFxIzVFsO_k"
   },
   "outputs": [],
   "source": [
    "!python3 finetune.py -p path/to/saved/model -m ssim -t float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRpMRL_AnTwU"
   },
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5-ewa1RjXGX"
   },
   "outputs": [],
   "source": [
    "# This script classifies test images using the minimum defect area and threshold previously approximated at the finetuning step.\n",
    "\n",
    "# usage: test.py [-h] -p [-s]\n",
    "\n",
    "# optional arguments: -h, --help show this help message and exit\n",
    "\n",
    "# -p , --path path to saved model\n",
    "\n",
    "# -s, --save save segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zZhWZ7Tsfhm"
   },
   "outputs": [],
   "source": [
    "!python3 test.py -p path/to/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuLdH362nXt2"
   },
   "source": [
    "#Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-8m8Aj-jXJP"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import shlex\n",
    "import time\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "from processing import utils\n",
    "from processing import postprocessing\n",
    "from processing.preprocessing import Preprocessor\n",
    "from processing.preprocessing import get_preprocessing_function\n",
    "from processing.postprocessing import label_images\n",
    "from processing.utils import printProgressBar\n",
    "from skimage.util import img_as_ubyte\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import seaborn as sn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt    \n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "import keras\n",
    "from autoencoder import losses\n",
    "from autoencoder import metrics\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3HSqWzbjXMJ"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOhveVSqjXPB"
   },
   "outputs": [],
   "source": [
    "def Test(args, th):\n",
    "  model_path = args.path\n",
    "  # load model and info\n",
    "  model = load_model(model_path,\n",
    "                      custom_objects={\n",
    "                \"LeakyReLU\": keras.layers.LeakyReLU,\n",
    "                \"loss\": losses.ssim_loss(1.0),\n",
    "                \"ssim\": metrics.ssim_metric(1.0),\n",
    "            },\n",
    "            compile=True,\n",
    "                      )\n",
    "  # set parameters\n",
    "  info = utils.get_model_info(model_path)\n",
    "  input_directory = info[\"data\"][\"input_directory\"]\n",
    "  architecture = info[\"model\"][\"architecture\"]\n",
    "  loss = info[\"model\"][\"loss\"]\n",
    "  rescale = info[\"preprocessing\"][\"rescale\"]\n",
    "  shape = info[\"preprocessing\"][\"shape\"]\n",
    "  color_mode = info[\"preprocessing\"][\"color_mode\"]\n",
    "  vmin = info[\"preprocessing\"][\"vmin\"]\n",
    "  vmax = info[\"preprocessing\"][\"vmax\"]\n",
    "  nb_validation_images = info[\"data\"][\"nb_validation_images\"]\n",
    "\n",
    "  preprocessing_function = get_preprocessing_function(architecture)\n",
    "  # # initialize preprocessor\n",
    "  preprocessor = Preprocessor(\n",
    "      input_directory=input_directory,\n",
    "      rescale=rescale,\n",
    "      shape=shape,\n",
    "      color_mode=color_mode,\n",
    "      preprocessing_function=preprocessing_function,\n",
    "  )\n",
    "\n",
    "  tst_img_list = [glob.glob(args.tst_pth + \"/good/*.jpeg\"), glob.glob(args.tst_pth + \"/defect/*.jpeg\")]\n",
    "  tst_lbl_list = [list (np.ones(len(tst_img_list[0]))), list (np.zeros(len(tst_img_list[1])))]\n",
    "  tst_prd_list = [list (np.ones(len(tst_img_list[0]))), list (np.zeros(len(tst_img_list[1])))]\n",
    "\n",
    "  tst_img_list = tst_img_list[0] + tst_img_list[1]\n",
    "  tst_lbl_list = tst_lbl_list[0] + tst_lbl_list[1]\n",
    "  tst_prd_list = tst_prd_list[0] + tst_prd_list[1]\n",
    "  \n",
    "  for i,img_nm in enumerate(tst_img_list):\n",
    "    img = preprocessor.get_test_image(img_nm)\n",
    "    imgs_test_pred = model.predict(img)\n",
    "    \n",
    "    ssim_l = 0\n",
    "    \n",
    "    for pat in range(20):\n",
    "        x = random.randint(0, 256)\n",
    "        y = random.randint(0, 256)\n",
    "        imgs_test_pred_pth = imgs_test_pred.reshape((512,512))\n",
    "        imgs_test_pred_pth = imgs_test_pred_pth[y: y + 256, x: x + 256]\n",
    "        \n",
    "        img_pth = img.reshape((512,512))\n",
    "        img_pth = img_pth[y: y + 256, x: x + 256]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        img_pth = img_pth.reshape(256,256)\n",
    "        imgs_test_pred_pth = imgs_test_pred_pth.reshape(256,256)\n",
    "        \n",
    "        ssim_ = ssim(img_pth, imgs_test_pred_pth, data_range=imgs_test_pred_pth.max() - imgs_test_pred_pth.min(), full = True)\n",
    "        \n",
    "        val = 1- ssim_[0]\n",
    "        ssim_l+=val\n",
    "    ssim_l = ssim_l/20\n",
    "        \n",
    "    \n",
    "    print(\"cnt_1\", f\" :{ssim_l}\",tst_img_list[i], f\" count: {ssim_l}\")\n",
    "\n",
    "    \n",
    "    if ssim_l > th:\n",
    "      tst_prd_list[i] = 0\n",
    "    else:\n",
    "      tst_prd_list[i] = 1\n",
    "\n",
    "# confusion matrix\n",
    "  matrix = confusion_matrix(tst_lbl_list,tst_prd_list, labels=[1,0])\n",
    "  print('Classification report : \\n',matrix)\n",
    "  return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rw_LsUTMWTwu"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser() \n",
    "parser.add_argument(\"-p\",\n",
    "    \"--path\", type=str, default= None ,required=True, metavar=\"\", help=\"path to saved model\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-i\", \"--img_pth\", type=str, default = 'None', help=\"save segmented images\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "     \"--tst_pth\", type=str, default = None, help=\"path to test folder\",\n",
    ")\n",
    "\n",
    "notebook_args = f\"\"\"\n",
    "--path \"./saved_models/data/can/mvtecCAE/ssim/7 gaussian_worked_v6/ad_model.h5\"\n",
    "--img_pth \"./data/can/test/good/20210914-180510.138.jpeg\"\n",
    "--tst_pth \"./data/can/test_\"\n",
    "\"\"\"\n",
    "args = parser.parse_args(shlex.split(notebook_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = Test(args, 0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= plt.subplot()\n",
    "sns.heatmap(matr, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['good', 'defect']); ax.yaxis.set_ticklabels(['good', 'defect']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k1HvJ0McZfN"
   },
   "outputs": [],
   "source": [
    "def inference(args, th):\n",
    "    # parse arguments\n",
    "    model_path = args.path\n",
    "    # ============= LOAD MODEL AND PREPROCESSING CONFIGURATION ================\n",
    "    # load model and info\n",
    "    model = load_model(model_path,\n",
    "                      custom_objects={\n",
    "                \"LeakyReLU\": keras.layers.LeakyReLU,\n",
    "                \"loss\": losses.ssim_loss(1.0),\n",
    "                \"ssim\": metrics.ssim_metric(1.0),\n",
    "            },\n",
    "            compile=True,\n",
    "                      )\n",
    "  # set parameters\n",
    "    info = utils.get_model_info(model_path)\n",
    "    # set parameters\n",
    "    input_directory = info[\"data\"][\"input_directory\"]\n",
    "    architecture = info[\"model\"][\"architecture\"]\n",
    "    loss = info[\"model\"][\"loss\"]\n",
    "    rescale = info[\"preprocessing\"][\"rescale\"]\n",
    "    shape = info[\"preprocessing\"][\"shape\"]\n",
    "    color_mode = info[\"preprocessing\"][\"color_mode\"]\n",
    "    vmin = info[\"preprocessing\"][\"vmin\"]\n",
    "    vmax = info[\"preprocessing\"][\"vmax\"]\n",
    "    nb_validation_images = info[\"data\"][\"nb_validation_images\"]\n",
    "\n",
    "    \n",
    "\n",
    "    #     # get the correct preprocessing function\n",
    "    preprocessing_function = get_preprocessing_function(architecture)\n",
    "\n",
    "    # # initialize preprocessor\n",
    "    preprocessor = Preprocessor(\n",
    "        input_directory=input_directory,\n",
    "        rescale=rescale,\n",
    "        shape=shape,\n",
    "        color_mode=color_mode,\n",
    "        preprocessing_function=preprocessing_function,\n",
    "    )\n",
    "\n",
    "    # get test image\n",
    "    img = preprocessor.get_test_image(args.img_pth)\n",
    "    \n",
    "    flp_img = np.flip(img, axis = 2)\n",
    "    plt.imshow(flp_img.reshape(512,512), cmap=\"gray\")\n",
    "    plt.show()\n",
    "#     x = random.randint(0, 256)\n",
    "#     y = random.randint(0, 256)\n",
    "#     img = img.reshape((512,512))\n",
    "#     img = img[y: y + 256, x: x + 256]\n",
    "#     img = cv2.resize(img, (512,512), interpolation = cv2.INTER_AREA)\n",
    "#     img = img.reshape(1,512,512,1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    plt.imshow(img.reshape(512,512), cmap='gray')\n",
    "    plt.show()\n",
    "    #predict on test image\n",
    "    start_time = time.time()\n",
    "\n",
    "    imgs_test_pred = model.predict(img)\n",
    "    imgs_test_pred_flp = model.predict(flp_img)\n",
    "    \n",
    "    img_t = tf.convert_to_tensor(img, np.float32)\n",
    "    img_pred__t = tf.convert_to_tensor(imgs_test_pred, np.float32)\n",
    "    ssim_loss = 1 - tf.image.ssim(img_t, img_pred__t, 1)\n",
    "    print(ssim_loss)\n",
    "    \n",
    "    plt.imshow(imgs_test_pred.reshape(512,512), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "#     ssim_ = ssim(img.reshape((512,512)), imgs_test_pred.reshape((512,512)), data_range=img.max() - img.min(), full = True)\n",
    "# #     ssim_ = np.asarray(ssim_)\n",
    "#     ssim_ = ssim_[1]\n",
    "#     ssim_ = 1 - ((ssim_ - np.min(ssim_))/np.ptp(ssim_))\n",
    "#     print(ssim_.shape)\n",
    "#     plt.imshow(ssim_.reshape(512,512), cmap='gray')\n",
    "#     plt.show()\n",
    "    \n",
    "#     ssim_ = -1 * ssim_ * np.log(ssim_)\n",
    "#     plt.imshow(ssim_)\n",
    "#     plt.show()\n",
    "#     arr = np.where(ssim_ > 0.36, 1.0,0)\n",
    "    \n",
    "    \n",
    "    map_ = np.sqrt((imgs_test_pred - img)**2)\n",
    "    map_ = ((map_ - np.min(map_))/np.ptp(map_))\n",
    "    \n",
    "    plt.imshow(map_.reshape(512,512), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "#     ent = -1 * map_ * np.log(map_)\n",
    "    end_map = np.where(map_ > 0.6, 1.0,0)\n",
    "#     plt.imshow(ent.reshape((512,512)))\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     map_ = glb_mask * arr\n",
    "#     cnt_n = np.count_nonzero(map_)\n",
    "#     print(cnt_n)\n",
    "    \n",
    "#     plt.imshow(arr.reshape(512,512), cmap=\"gray\")\n",
    "#     plt.show()\n",
    "    \n",
    "    plt.imshow(end_map.reshape(512,512), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-----------------\")\n",
    "    map_ = np.sqrt((imgs_test_pred_flp - flp_img)**2)\n",
    "    map_ = ((map_ - np.min(map_))/np.ptp(map_))\n",
    "    \n",
    "    plt.imshow(map_.reshape(512,512), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "#     ent = -1 * map_ * np.log(map_)\n",
    "    end_map = np.where(map_ > 0.6, 1.0,0)\n",
    "    \n",
    "    plt.imshow(end_map.reshape(512,512), cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shp = 512\n",
    "cnt = int(img_shp/2)\n",
    "glb_mask = cv2.circle(np.zeros((img_shp, img_shp)), (cnt-10, cnt-10), cnt , (1,1,1), -1) \n",
    "glb_mask = np.array(glb_mask, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2930,
     "status": "ok",
     "timestamp": 1632172229307,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699857406068047110"
     },
     "user_tz": -300
    },
    "id": "5qsSpZdGEX-Z",
    "outputId": "66a684b8-d5a3-4cc1-b3ae-d27f92fa5070",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference(args, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_algo(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MVTec_Quick (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
