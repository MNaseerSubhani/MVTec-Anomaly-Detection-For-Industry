{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MVTec_Quick.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1etDNuG2o9jjrAgBM31z27IAiEn8HVucy","authorship_tag":"ABX9TyOaXQW2PvzSyG09k6PGSeah"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YBqL4W8Chxi9"},"source":["#Introduction"]},{"cell_type":"markdown","metadata":{"id":"5tVeHtQDhzed"},"source":["This notebook is a easy guide for training and testing of anomaly detection based on MVTec https://github.com/AdneneBoumessouer/MVTec-Anomaly-Detection."]},{"cell_type":"code","metadata":{"id":"S_WPNR8qmHsq"},"source":["!pip3 install ktrain"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uESknW72h8u5"},"source":["###Link Google Drive"]},{"cell_type":"code","metadata":{"id":"sUcdjkC3hHYE"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxo8GmWVcM61","executionInfo":{"status":"ok","timestamp":1625312270599,"user_tz":0,"elapsed":582,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}},"outputId":"a8ca3a9e-23e9-43ce-f403-645193d0fe4d"},"source":["%cd /content/drive/MyDrive/MVTec-Anomaly-Detection-For-Industry"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/MVTec-Anomaly-Detection-For-Industry\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MecSmAFxlX66"},"source":["#Dataset "]},{"cell_type":"markdown","metadata":{"id":"Z5ZvfjkglvRL"},"source":["### Directory Structure using your own dataset"]},{"cell_type":"markdown","metadata":{"id":"j1UD1k1Blj6E"},"source":["To train with your own dataset, you need to have a comparable directory structure. For example:"]},{"cell_type":"code","metadata":{"id":"08vGmfeplXv0","executionInfo":{"status":"ok","timestamp":1625302766509,"user_tz":0,"elapsed":461,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}}},"source":["#data\n","  #├── class1\n","  # │   ├── test\n","  # │   │   ├── good\n","  # │   │   ├── defect\n","  # │   └── train\n","  # │       └── good\n","  # ├── class2\n","  # │   ├── test\n","  # │   │   ├── good\n","  # │   │   ├── defect\n","  # │   └── train\n","  # │       └── good\n","  # ...\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aacA9vucmQHq"},"source":["#Training "]},{"cell_type":"code","metadata":{"id":"8vn8bS_JnGwj"},"source":["# During training, the CAE trains exclusively on defect-free images and learns to reconstruct (predict) defect-free training samples.\n","\n","# usage: train.py [-h] -d [-a] [-c] [-l] [-b] [-i]\n","\n","# optional arguments:\n","\n","# -h, --help show this help message and exit\n","\n","# -d , --input-dir directory containing training images\n","\n","# -a , --architecture architecture of the model to use for training: 'mvtecCAE', 'baselineCAE', 'inceptionCAE' or 'resnetCAE'\n","\n","# -c , --color color mode for preprocessing images before training: 'rgb' or 'grayscale'\n","\n","# -l , --loss loss function to use for training: 'mssim', 'ssim' or 'l2'\n","\n","# -b , --batch batch size to use for training\n","\n","# -i, --inspect generate inspection plots after training\n","\n","# Example usage:\n","\n","# python3 train.py -d mvtec/capsule -a mvtecCAE -b 8 -l ssim -c grayscale\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7yvOxdedpRS"},"source":["!python3 train.py -d data/can -a baselineCAE -b 8 -l ssim -c grayscale"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXNG2EaPnOBF"},"source":["#Finetune "]},{"cell_type":"code","metadata":{"id":"LBKfp4uCjXDo"},"source":["# This script used a subset of defect-free training images and a subset of both defect and defect-free test images to determine good values for minimum defect area and threshold pair of parameters that will be used during testing for classification and segmentation.\n","\n","# usage: finetune.py [-h] -p [-m] [-t]\n","\n","# optional arguments: -h, --help show this help message and exit\n","\n","# -p , --path path to saved model\n","\n","# -m , --method method for generating resmaps: 'ssim' or 'l2'\n","\n","# -t , --dtype datatype for processing resmaps: 'float64' or 'uint8'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuFxIzVFsO_k"},"source":["!python3 finetune.py -p path/to/saved/model -m ssim -t float64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRpMRL_AnTwU"},"source":["#Testing"]},{"cell_type":"code","metadata":{"id":"l5-ewa1RjXGX"},"source":["# This script classifies test images using the minimum defect area and threshold previously approximated at the finetuning step.\n","\n","# usage: test.py [-h] -p [-s]\n","\n","# optional arguments: -h, --help show this help message and exit\n","\n","# -p , --path path to saved model\n","\n","# -s, --save save segmented images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zZhWZ7Tsfhm"},"source":["!python3 test.py -p path/to/model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuLdH362nXt2"},"source":["#Inference "]},{"cell_type":"code","metadata":{"id":"k-8m8Aj-jXJP","executionInfo":{"status":"ok","timestamp":1625312300239,"user_tz":0,"elapsed":1546,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}}},"source":["from skimage.measure import compare_ssim\n","import sys\n","import os\n","import argparse\n","from pathlib import Path\n","import shlex\n","import time\n","import json\n","import tensorflow as tf\n","from processing import utils\n","from processing import postprocessing\n","from processing.preprocessing import Preprocessor\n","from processing.preprocessing import get_preprocessing_function\n","from processing.postprocessing import label_images\n","from processing.utils import printProgressBar\n","from skimage.util import img_as_ubyte\n","from sklearn.metrics import confusion_matrix\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import logging"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3HSqWzbjXMJ","executionInfo":{"status":"ok","timestamp":1625312300239,"user_tz":0,"elapsed":6,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}}},"source":["logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOhveVSqjXPB","executionInfo":{"status":"ok","timestamp":1625312300239,"user_tz":0,"elapsed":4,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}}},"source":["\n","def get_true_classes(filenames):\n","    # retrieve ground truth\n","    y_true = [1 if \"good\" not in filename.split(\"/\") else 0 for filename in filenames]\n","    return y_true\n","\n","\n","def is_defective(areas, min_area):\n","    \"\"\"Decides if image is defective given the areas of its connected components\"\"\"\n","    areas = np.array(areas)\n","    if areas[areas >= min_area].shape[0] > 0:\n","        return 1\n","    return 0\n","\n","\n","def predict_classes(resmaps, min_area, threshold):\n","    # threshold residual maps with the given threshold\n","    resmaps_th = resmaps > threshold\n","    # compute connected components\n","    _, areas_all = label_images(resmaps_th)\n","    # Decides if images are defective given the areas of their connected components\n","    y_pred = [is_defective(areas, min_area) for areas in areas_all]\n","    return y_pred\n","\n","\n","def save_segmented_images(resmaps, threshold, filenames, save_dir):\n","    # threshold residual maps with the given threshold\n","    resmaps_th = resmaps > threshold\n","    # create directory to save segmented resmaps\n","    seg_dir = os.path.join(save_dir, \"segmentation\")\n","    if not os.path.isdir(seg_dir):\n","        os.makedirs(seg_dir)\n","    # save segmented resmaps\n","    for i, resmap_th in enumerate(resmaps_th):\n","        fname = utils.generate_new_name(filenames[i], suffix=\"seg\")\n","        fpath = os.path.join(seg_dir, fname)\n","        plt.imsave(fpath, resmap_th, cmap=\"gray\")\n","    return\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"1k1HvJ0McZfN","executionInfo":{"status":"ok","timestamp":1625312394340,"user_tz":0,"elapsed":708,"user":{"displayName":"Muhammad Naseer Subhani","photoUrl":"","userId":"06699857406068047110"}}},"source":["\n","def main(args):\n","    # parse arguments\n","    model_path = args.path\n","\n","    # ============= LOAD MODEL AND PREPROCESSING CONFIGURATION ================\n","\n","    # load model and info\n","    model, info, _ = utils.load_model_HDF5(model_path)\n","    # set parameters\n","    input_directory = info[\"data\"][\"input_directory\"]\n","    architecture = info[\"model\"][\"architecture\"]\n","    loss = info[\"model\"][\"loss\"]\n","    rescale = info[\"preprocessing\"][\"rescale\"]\n","    shape = info[\"preprocessing\"][\"shape\"]\n","    color_mode = info[\"preprocessing\"][\"color_mode\"]\n","    vmin = info[\"preprocessing\"][\"vmin\"]\n","    vmax = info[\"preprocessing\"][\"vmax\"]\n","    nb_validation_images = info[\"data\"][\"nb_validation_images\"]\n","\n","    # =================== LOAD VALIDATION PARAMETERS =========================\n","\n","    # model_dir_name = os.path.basename(str(Path(model_path).parent))\n","    # finetune_dir = os.path.join(\n","    #     os.getcwd(),\n","    #     \"results\",\n","    #     input_directory,\n","    #     architecture,\n","    #     loss,\n","    #     model_dir_name,\n","    #     \"finetuning\",\n","    # )\n","    # subdirs = os.listdir(finetune_dir)\n","    # for subdir in subdirs:\n","    #     logger.info(\n","    #         \"testing with finetuning parameters from \\n{}...\".format(\n","    #             os.path.join(finetune_dir, subdir)\n","    #         )\n","    #     )\n","    #     try:\n","    #         with open(\n","    #             os.path.join(finetune_dir, subdir, \"finetuning_result.json\"), \"r\"\n","    #         ) as read_file:\n","    #             validation_result = json.load(read_file)\n","    #     except FileNotFoundError:\n","    #         logger.warning(\"run finetune.py before testing.\\nexiting script.\")\n","    #         sys.exit()\n","\n","    min_area = 2\n","    threshold = 0.2\n","    method = 0.2\n","    dtype = 'float64'\n","\n","    #     # ====================== PREPROCESS TEST IMAGES ==========================\n","\n","    #     # get the correct preprocessing function\n","    preprocessing_function = get_preprocessing_function(architecture)\n","\n","    # # initialize preprocessor\n","    preprocessor = Preprocessor(\n","        input_directory=input_directory,\n","        rescale=rescale,\n","        shape=shape,\n","        color_mode=color_mode,\n","        preprocessing_function=preprocessing_function,\n","    )\n","\n","    # get test image\n","    img = preprocessor.get_test_image(args.img_pth)\n","    plt.imshow(img.reshape(128,128), cmap='gray')\n","    plt.show()\n","    #predict on test image\n","    start_time = time.time()\n","\n","    imgs_test_pred = model.predict(img)\n","    map = np.sqrt((imgs_test_pred - img)**2)\n","\n","    print(\"--- %s seconds ---\" % (time.time() - start_time))\n","\n","    plt.imshow(imgs_test_pred.reshape(128,128), cmap='gray')\n","    plt.show()\n","\n","    map = np.where(map> 0.5,1,0)\n","    plt.imshow(map.reshape(128,128), cmap='gray')\n","    plt.show()\n","\n","    (score, diff ) = compare_ssim(imgs_test_pred.reshape(128,128)*255, img.reshape(128,128)*255, full=True)\n","    diff = (diff * 255) \n","    print(score)\n","    plt.imshow(diff, cmap = 'gray')\n","    plt.show()\n","\n","    #     # instantiate TensorImages object\n","    #     tensor_test = postprocessing.TensorImages(\n","    #         imgs_input=imgs_test_input,\n","    #         imgs_pred=imgs_test_pred,\n","    #         vmin=vmin,\n","    #         vmax=vmax,\n","    #         method=method,\n","    #         dtype=dtype,\n","    #         filenames=filenames,\n","    #     )\n","\n","    #     # ====================== CLASSIFICATION ==========================\n","\n","    #     # retrieve ground truth\n","    #     y_true = get_true_classes(filenames)\n","\n","    #     # predict classes on test images\n","    #     y_pred = predict_classes(\n","    #         resmaps=tensor_test.resmaps, min_area=min_area, threshold=threshold\n","    #     )\n","\n","    #     # confusion matrix\n","    #     tnr, fp, fn, tpr = confusion_matrix(y_true, y_pred, normalize=\"true\").ravel()\n","\n","    #     # initialize dictionary to store test results\n","    #     test_result = {\n","    #         \"min_area\": min_area,\n","    #         \"threshold\": threshold,\n","    #         \"TPR\": tpr,\n","    #         \"TNR\": tnr,\n","    #         \"score\": (tpr + tnr) / 2,\n","    #         \"method\": method,\n","    #         \"dtype\": dtype,\n","    #     }\n","\n","    #     # ====================== SAVE TEST RESULTS =========================\n","\n","    #     # create directory to save test results\n","    #     save_dir = os.path.join(\n","    #         os.getcwd(),\n","    #         \"results\",\n","    #         input_directory,\n","    #         architecture,\n","    #         loss,\n","    #         model_dir_name,\n","    #         \"test\",\n","    #         subdir,\n","    #     )\n","\n","    #     if not os.path.isdir(save_dir):\n","    #         os.makedirs(save_dir)\n","\n","    #     # save test result\n","    #     with open(os.path.join(save_dir, \"test_result.json\"), \"w\") as json_file:\n","    #         json.dump(test_result, json_file, indent=4, sort_keys=False)\n","\n","    #     # save classification of image files in a .txt file\n","    #     classification = {\n","    #         \"filenames\": filenames,\n","    #         \"predictions\": y_pred,\n","    #         \"truth\": y_true,\n","    #         \"accurate_predictions\": np.array(y_true) == np.array(y_pred),\n","    #     }\n","    #     df_clf = pd.DataFrame.from_dict(classification)\n","    #     with open(os.path.join(save_dir, \"classification.txt\"), \"w\") as f:\n","    #         f.write(\n","    #             \"min_area = {}, threshold = {}, method = {}, dtype = {}\\n\\n\".format(\n","    #                 min_area, threshold, method, dtype\n","    #             )\n","    #         )\n","    #         f.write(df_clf.to_string(header=True, index=True))\n","\n","    #     # print classification results to console\n","    #     with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n","    #         print(df_clf)\n","\n","    #     # save segmented resmaps\n","    #     #if save:\n","    #     save_segmented_images(tensor_test.resmaps, threshold, filenames, save_dir)\n","\n","    #     # print test_results to console\n","    #     print(\"test results: {}\".format(test_result))\n","\n","\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKHJTa_Gcoe-"},"source":["if __name__ == \"__main__\":\n","    # create parser\n","    parser = argparse.ArgumentParser()\n","    \n","    parser.add_argument(\"-p\",\n","        \"--path\", type=str, default= 'saved_models/ad_data/can/baselineCAE/ssim/06-05-2021_02-02-52/baselineCAE_b2_e100.hdf5' ,required=True, metavar=\"\", help=\"path to saved model\"\n","    )\n","    parser.add_argument(\n","        \"-i\", \"--img_pth\", type=str, default = 'ad_data/can/test/defect/1665.jpg', help=\"save segmented images\",\n","    )\n","\n","\n","    notebook_args = f\"\"\"\n","    --path \"saved_models/data/can/baselineCAE/ssim/03-07-2021_09-02-52/baselineCAE_b8_e12.hdf5\"\n","    --img_pth \"data/can/test/defect/1739.jpg\"\n","    \"\"\"\n","    args = parser.parse_args(shlex.split(notebook_args))\n","\n","    main(args)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2usaZ4Isohi"},"source":[""],"execution_count":null,"outputs":[]}]}